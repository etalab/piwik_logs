{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import pickle\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from unidecode import unidecode\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse actions to dataset ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regex_home = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/$'\n",
    "regex_datasets_page = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/datasets/$'\n",
    "regex_datasets = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/datasets/([a-z\\-0-9]+)/$'\n",
    "regex_datasets_search = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/datasets/\\?'\n",
    "regex_organizations = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/organizations/'\n",
    "regex_reuses = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/reuses/'\n",
    "regex_territory = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/territory/'\n",
    "regex_topics = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/topics/'\n",
    "regex_town = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/town/'\n",
    "regex_users = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/users/'\n",
    "regex_search = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/search/'\n",
    "regex_posts = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/posts/'\n",
    "regex_faq = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/faq/'\n",
    "regex_dashboard = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/dashboard/'\n",
    "regex_apidoc = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/apidoc/'\n",
    "regex_groups = r'^https?://www\\.data\\.gouv\\.fr/groups/'\n",
    "regex_reference = r'^https?://www\\.data\\.gouv\\.fr/(?:fr|en|es)/reference$'\n",
    "regex_id = r'^https?://id\\.data\\.gouv\\.fr/'\n",
    "regex_api_spatial = r'^https?://www\\.data\\.gouv\\.fr/api/1/spatial/'\n",
    "regex_api_discussions = r'^https?://www\\.data\\.gouv\\.fr/api/1/discussions/\\?'\n",
    "regex_api_issues = r'^https?://www\\.data\\.gouv\\.fr/api/1/issues/\\?'\n",
    "regex_api_swagger = r'^https?://www\\.data\\.gouv\\.fr/api/1/swagger\\.json'\n",
    "regex_api_datasets_frequencies = r'^https?://www\\.data\\.gouv\\.fr/api/1/datasets/frequencies/'\n",
    "regex_api_reuses = r'^https?://www\\.data\\.gouv\\.fr/api/1/reuses/'\n",
    "regex_api_metrics = r'^https?://www\\.data\\.gouv\\.fr/api/1/metrics/'\n",
    "regex_api_activity = r'^https?://www\\.data\\.gouv\\.fr/api/1/activity'\n",
    "regex_api_organizations = r'^https?://www\\.data\\.gouv\\.fr/api/1/organizations/'\n",
    "regex_api_datasets = r'^https?://www\\.data\\.gouv\\.fr/api/1/datasets/([a-z\\-0-9]+)/'\n",
    "regex_api_datasets_search = r'^https?://www\\.data\\.gouv\\.fr/api/1/datasets/\\?'\n",
    "regex_api_community = r'^https?://www\\.data\\.gouv\\.fr/api/1/datasets/community_resources/\\?'\n",
    "regex_api_oembeds = r'^https?://www\\.data\\.gouv\\.fr/api/1/oembeds/'\n",
    "regex_api_me = r'^https?://www\\.data\\.gouv\\.fr/api/1/me/'\n",
    "regex_api_site = r'^https?://www\\.data\\.gouv\\.fr/api/1/site/'\n",
    "regex_api_users = r'^https?://www\\.data\\.gouv\\.fr/api/1/users/'\n",
    "regex_api_transfer = r'^https?://www\\.data\\.gouv\\.fr/api/1/transfer/'\n",
    "regex_api_harvest = r'^https?://www\\.data\\.gouv\\.fr/api/1/harvest/'\n",
    "\n",
    "\n",
    "def parse_visits(visits):\n",
    "    unhandled_actions = []\n",
    "    visits_parsed = []\n",
    "    for visit in visits:\n",
    "        visit_parsed = []\n",
    "        for action in visit['actions']:\n",
    "            match_home = re.match(regex_home, action['url'])\n",
    "            match_datasets_page = re.match(regex_datasets_page, action['url'])\n",
    "            match_datasets = re.match(regex_datasets, action['url'])\n",
    "            match_datasets_search = re.match(regex_datasets_search, action['url'])\n",
    "            match_organizations = re.match(regex_organizations, action['url'])\n",
    "            match_reuses = re.match(regex_reuses, action['url'])\n",
    "            match_territory = re.match(regex_territory, action['url'])\n",
    "            match_topics = re.match(regex_topics, action['url'])\n",
    "            match_town = re.match(regex_town, action['url'])\n",
    "            match_users = re.match(regex_users, action['url'])\n",
    "            match_search = re.match(regex_search, action['url'])\n",
    "            match_posts = re.match(regex_posts, action['url'])\n",
    "            match_faq = re.match(regex_faq, action['url'])\n",
    "            match_dashboard = re.match(regex_dashboard, action['url'])\n",
    "            match_apidoc = re.match(regex_apidoc, action['url'])\n",
    "            match_groups = re.match(regex_groups, action['url'])\n",
    "            match_reference = re.match(regex_reference, action['url'])\n",
    "            match_id = re.match(regex_id, action['url'])\n",
    "            match_api_spatial = re.match(regex_api_spatial, action['url'])\n",
    "            match_api_discussions = re.match(regex_api_discussions, action['url'])\n",
    "            match_api_issues = re.match(regex_api_issues, action['url'])\n",
    "            match_api_swagger = re.match(regex_api_swagger, action['url'])\n",
    "            match_api_datasets_frequencies = re.match(regex_api_datasets_frequencies, action['url'])\n",
    "            match_api_reuses = re.match(regex_api_reuses, action['url'])                \n",
    "            match_api_metrics = re.match(regex_api_metrics, action['url'])                \n",
    "            match_api_activity = re.match(regex_api_activity, action['url'])                \n",
    "            match_api_organizations = re.match(regex_api_organizations, action['url'])                \n",
    "            match_api_datasets = re.match(regex_api_datasets, action['url'])                \n",
    "            match_api_datasets_search = re.match(regex_api_datasets_search, action['url'])                \n",
    "            match_api_community = re.match(regex_api_community, action['url'])                \n",
    "            match_api_oembeds = re.match(regex_api_oembeds, action['url'])                \n",
    "            match_api_me = re.match(regex_api_me, action['url'])                \n",
    "            match_api_site = re.match(regex_api_site, action['url'])                \n",
    "            match_api_users = re.match(regex_api_users, action['url'])                \n",
    "            match_api_transfer = re.match(regex_api_transfer, action['url'])                \n",
    "            match_api_harvest = re.match(regex_api_harvest, action['url'])                \n",
    "            \n",
    "            if action['type'] == 'search':\n",
    "                visit_parsed.append(('keyword', action['keyword']))\n",
    "                \n",
    "            elif action['type'] == 'action':\n",
    "                if match_home:\n",
    "                    pass\n",
    "                elif match_datasets_page:\n",
    "                    pass\n",
    "                elif match_datasets:\n",
    "                    dataset_slug = match_datasets.groups()[0]\n",
    "                    visit_parsed.append(('slug_or_id', dataset_slug))\n",
    "                elif match_datasets_search:\n",
    "                    pass\n",
    "                elif match_organizations:\n",
    "                    pass\n",
    "                elif match_reuses:\n",
    "                    pass\n",
    "                elif match_territory:\n",
    "                    pass\n",
    "                elif match_topics:\n",
    "                    pass\n",
    "                elif match_town:\n",
    "                    pass\n",
    "                elif match_users:\n",
    "                    pass\n",
    "                elif match_search:\n",
    "                    pass\n",
    "                elif match_posts:\n",
    "                    pass\n",
    "                elif match_faq:\n",
    "                    pass\n",
    "                elif match_dashboard:\n",
    "                    pass\n",
    "                elif match_apidoc:\n",
    "                    pass\n",
    "                elif match_groups:\n",
    "                    pass\n",
    "                elif match_reference:\n",
    "                    pass\n",
    "                elif match_id:\n",
    "                    pass\n",
    "                elif match_api_spatial:\n",
    "                    pass\n",
    "                elif match_api_discussions:\n",
    "                    parsed = urllib.parse.urlparse(action['url'])\n",
    "                    params = urllib.parse.parse_qs(parsed.query)\n",
    "                    if 'for' in params:\n",
    "                        dataset_id = params['for'][0]\n",
    "                        visit_parsed.append(('id', dataset_id))\n",
    "                elif match_api_issues:\n",
    "                    parsed = urllib.parse.urlparse(action['url'])\n",
    "                    params = urllib.parse.parse_qs(parsed.query)\n",
    "                    if 'for' in params:\n",
    "                        dataset_id = params['for'][0]\n",
    "                        visit_parsed.append(('id', dataset_id))\n",
    "                elif match_api_swagger:\n",
    "                    pass\n",
    "                elif match_api_datasets_frequencies:\n",
    "                    pass\n",
    "                elif match_api_reuses:\n",
    "                    pass\n",
    "                elif match_api_metrics:\n",
    "                    pass\n",
    "                elif match_api_activity:\n",
    "                    pass\n",
    "                elif match_api_organizations:\n",
    "                    pass\n",
    "                elif match_api_datasets:\n",
    "                    dataset_id = match_api_datasets.groups()[0]\n",
    "                    visit_parsed.append(('slug_or_id', dataset_id))\n",
    "                elif match_api_datasets_search:\n",
    "                    pass\n",
    "                elif match_api_community:\n",
    "                    parsed = urllib.parse.urlparse(action['url'])\n",
    "                    params = urllib.parse.parse_qs(parsed.query)\n",
    "                    if 'for' in params:\n",
    "                        dataset_id = params['for'][0]\n",
    "                        visit_parsed.append(('id', dataset_id))\n",
    "                elif match_api_oembeds:\n",
    "                    pass\n",
    "                elif match_api_me:\n",
    "                    pass\n",
    "                elif match_api_site:\n",
    "                    pass\n",
    "                elif match_api_users:\n",
    "                    pass\n",
    "                elif match_api_transfer:\n",
    "                    pass\n",
    "                elif match_api_harvest:\n",
    "                    pass\n",
    "                else:\n",
    "                    unhandled_actions.append(action)\n",
    "                    \n",
    "            elif action['type'] == 'goal':               \n",
    "                if match_reuses:\n",
    "                    pass\n",
    "                elif match_datasets:\n",
    "                    dataset_slug = match_datasets.groups()[0]\n",
    "                    visit_parsed.append(('slug_or_id', dataset_slug))\n",
    "                elif match_api_reuses:\n",
    "                    pass\n",
    "                elif match_id:\n",
    "                    pass\n",
    "                elif match_api_organizations:\n",
    "                    pass\n",
    "                elif match_api_transfer:\n",
    "                    pass\n",
    "                else:\n",
    "                    unhandled_actions.append(action)\n",
    "                    \n",
    "            elif action['type'] == 'outlink':\n",
    "                pass\n",
    "            \n",
    "            elif action['type'] == 'download':\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                unhandled_actions.append(action)\n",
    "        visits_parsed.append(visit_parsed)\n",
    "        \n",
    "    return visits_parsed, unhandled_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'deduplicated_logs'\n",
    "target_dir = 'parsed_logs'\n",
    "\n",
    "filenames = glob.glob(source_dir + '/*')\n",
    "\n",
    "unhandled_actions = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        visits = json.load(f)\n",
    "    visits_parsed, unhandled_actions_file = parse_visits(visits)\n",
    "    unhandled_actions += unhandled_actions_file\n",
    "    with open(os.path.join(target_dir, os.path.basename(filename)), 'w') as f:\n",
    "        json.dump(visits_parsed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15534"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unhandled_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.data.gouv.fr/api/1/datasets/', 1630),\n",
       " ('https://www.data.gouv.fr/fr/terms/', 895),\n",
       " ('https://www.data.gouv.fr/api/1/discussions/', 819),\n",
       " ('https://www.data.gouv.fr/fr/dataconnexions-', 765),\n",
       " ('https://www.data.gouv.fr/datasets/extractio', 400),\n",
       " ('http://www.data.gouv.fr/donnees/view/Table-', 345),\n",
       " ('https://www.data.gouv.fr/fr/oauth/authorize', 332),\n",
       " ('https://www.data.gouv.fr/api/1/datasets/com', 310),\n",
       " ('https://www.data.gouv.fr/fr/credits/', 301),\n",
       " ('http://www.data.gouv.fr/fr/Redevances', 274),\n",
       " ('http://www.data.gouv.fr/fr/openfield16', 260),\n",
       " ('http://www.data.gouv.fr/DataSet/573376?xtmc', 235),\n",
       " ('https://www.data.gouv.fr/api/1/posts/58f9bb', 234),\n",
       " ('http://www.data.gouv.fr/content/search?Sear', 222),\n",
       " ('http://www.data.gouv.fr/DataSet/30382152', 217),\n",
       " ('https://www.data.gouv.fr/wiki/Outillage_pou', 195),\n",
       " ('http://www.data.gouv.fr/var/download/SSA4_A', 188),\n",
       " ('https://www.data.gouv.fr/frmetrics', 185),\n",
       " ('http://www.data.gouv.fr/api/1/discussions/', 175),\n",
       " ('https://www.data.gouv.fr/api/1/tags/suggest', 174),\n",
       " ('https://www.data.gouv.fr/fr/climate-change-', 172),\n",
       " ('https://www.data.gouv.fr/fr/nec-mergitur', 172),\n",
       " ('https://www.data.gouv.fr/api/1/datasets/536', 148),\n",
       " ('https://www.data.gouv.fr/fr/datasets/barome', 146),\n",
       " ('http://www.data.gouv.fr/fr/datasets/base-si', 142),\n",
       " ('http://www.data.gouv.fr/donnees/view/Adress', 142),\n",
       " ('https://www.data.gouv.fr/fr/datasets/electi', 116),\n",
       " ('http://www.data.gouv.fr/fr/reference?platfo', 100),\n",
       " ('http://www.data.gouv.fr/donnees/view/Liste-', 83),\n",
       " ('https://www.data.gouv.fr/fr/datasets/monres', 82)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter([s['url'][:43] for s in unhandled_actions])\n",
    "c.most_common(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deduplication + slug to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_info = pd.read_csv('datasets-2017-06-27-15-14.csv', sep=';')\n",
    "\n",
    "id2slug = {r[1]: r[3] for r in dataset_info.itertuples()}\n",
    "slug2id = {r[3]: r[1] for r in dataset_info.itertuples()}\n",
    "\n",
    "datasets = list(dataset_info.id)\n",
    "\n",
    "datasets_index = {dataset: i for i, dataset in enumerate(datasets)}\n",
    "datasets_set = set(datasets)\n",
    "slugs_set = set(slug2id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deduplicate(visits):\n",
    "    visits_dedup = []\n",
    "    for visit in visits:\n",
    "        visit_dedup = []\n",
    "        sets = {\n",
    "            'keyword': set(),\n",
    "            'id': set(),\n",
    "            'slug_or_id': set(),\n",
    "        }\n",
    "        for kind, value in visit:\n",
    "            if value not in sets[kind]:\n",
    "                sets[kind].add(value)\n",
    "                visit_dedup.append((kind, value))\n",
    "        visits_dedup.append(visit_dedup)\n",
    "    return visits_dedup\n",
    "\n",
    "def resolve_slugs(visits):\n",
    "    visits_clean = []\n",
    "    id_ok = 0\n",
    "    id_unknown = []\n",
    "    slug_ok = 0\n",
    "    slug_unknown = []\n",
    "    for visit in visits:\n",
    "        visit_clean = []\n",
    "        for kind, value in visit:\n",
    "            if kind == 'keyword':\n",
    "                visit_clean.append((kind, value))\n",
    "\n",
    "            elif kind == 'id':\n",
    "                if value in datasets_set:\n",
    "                    visit_clean.append((kind, value))\n",
    "                    id_ok += 1\n",
    "                else:\n",
    "                    id_unknown.append(value)\n",
    "\n",
    "            elif kind == 'slug_or_id':\n",
    "                if value in datasets_set:\n",
    "                    visit_clean.append(('id', value))\n",
    "                    id_ok += 1\n",
    "                elif value in slugs_set:\n",
    "                    dataset_id = slug2id[value]\n",
    "                    visit_clean.append(('id', dataset_id))\n",
    "                    slug_ok += 1\n",
    "                else:\n",
    "                    if re.match(r'^[0-9a-f]{24}$', value):\n",
    "                        id_unknown.append(value)\n",
    "                    else:\n",
    "                        slug_unknown.append(value)\n",
    "\n",
    "            else:\n",
    "                raise ValueError()\n",
    "        visits_clean.append(visit_clean)\n",
    "        \n",
    "    return visits_clean, id_ok, id_unknown, slug_ok, slug_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'parsed_logs'\n",
    "target_dir = 'clean_logs'\n",
    "\n",
    "filenames = glob.glob(source_dir + '/*')\n",
    "\n",
    "id_ok = 0\n",
    "id_unknown = []\n",
    "slug_ok = 0\n",
    "slug_unknown = []\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        visits_parsed = json.load(f)\n",
    "    \n",
    "    visits_dedup = deduplicate(visits_parsed)\n",
    "    visits_clean, id_ok_file, id_unknown_file, slug_ok_file, slug_unknown_file = resolve_slugs(visits_dedup)\n",
    "    \n",
    "    id_ok += id_ok_file\n",
    "    id_unknown += id_unknown_file\n",
    "    slug_ok += slug_ok_file\n",
    "    slug_unknown += slug_unknown_file\n",
    "        \n",
    "    with open(os.path.join(target_dir, os.path.basename(filename)), 'w') as f:\n",
    "        json.dump(visits_clean, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331082, 55968, 1216745, 52196)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_ok, len(id_unknown), slug_ok, len(slug_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547827, 108164, 0.0653167801032735, 0.9346832198967265)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_ok = id_ok + slug_ok\n",
    "sum_unknown = len(id_unknown) + len(slug_unknown)\n",
    "sum_ok, sum_unknown, sum_unknown / (sum_ok + sum_unknown), sum_ok / (sum_ok + sum_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\int_0^1{t_a^{x/2}dx}=0.8886215632082586$$\n",
    "\n",
    "$$x = \\frac{\\ln(t_a)}{2}, e^x-1 = 0.8886215632082586x$$\n",
    "\n",
    "$$x = -0.2410056126332082, t_a = 0.6175401296732944$$\n",
    "\n",
    "38% de turnover annuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57e1017b88ee38414d5ff491',\n",
       " '574da090c751df32e7535dd6',\n",
       " '574da090c751df32e7535dd6',\n",
       " '57e1017b88ee38414d5ff491',\n",
       " '574da090c751df32e7535dd6',\n",
       " '57e1017b88ee38414d5ff491',\n",
       " '57d16d62c751df60f597bae5',\n",
       " '5888e0ae88ee3808539b81a4',\n",
       " '5882a14ac751df3f9cae0a68',\n",
       " '5882a14ac751df3f9cae0a68']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_unknown[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chiffres-du-registre-des-francais-etablis-hors-de-france-pour-lannee-2015',\n",
       " 'montants-d-aides-pour-les-200-titres-de-presse-les-plus-aides',\n",
       " 'petites-regions-fourrageres-du-limousin',\n",
       " 'table-de-correspondance-des-communes-et-des-cantons-avec-les-circonscriptions-legislat-551418',\n",
       " 'niveau-des-debits-sur-les-reseaux-dacces-a-internet-adsl-cable-fibre-ftth-3',\n",
       " 'ppr-orthez-64ddtm20000008-zone-dinformations-dun-plan-de-prevention-du-risque-inondation-de-orthez-64430-departement-des-pyrenees-atlantiques',\n",
       " 'ppr-de-orthez-64ddtm20000008-plan-de-prevention-des-risques-naturels-pprn-de-la-commune-de-orthez-64430-departement-des-pyrenees-atlantiques',\n",
       " 'education-effectifs-des-ecoles-publiques-maternelles',\n",
       " 'badges',\n",
       " 'extraction-du-fichier-national-des-etablissements-sanitaires-et-sociaux-finess-par-etablissements']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slug_unknown[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extraction-du-fichier-national-des-etablissements-sanitaires-et-sociaux-finess-par-etablissements',\n",
       "  4016),\n",
       " ('chiffres-du-registre-des-francais-etablis-hors-de-france-pour-lannee-2015',\n",
       "  1794),\n",
       " ('table-de-correspondance-des-communes-et-des-cantons-avec-les-circonscriptions-legislat-551418',\n",
       "  1666),\n",
       " ('parrainages', 1409),\n",
       " ('resultats-du-vote-des-francais-residant-a-letranger-au-premier-tour-de-lelection-presidentielle-2017',\n",
       "  1406),\n",
       " ('badges', 1405),\n",
       " ('licenses', 1141),\n",
       " ('resultats-des-elections-presidentielles-par-commune', 987),\n",
       " ('plan-cadastral-informatise', 817),\n",
       " ('liste-des-bureaux-de-vote-prs', 801)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(slug_unknown)\n",
    "c.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_dir = 'clean_logs'\n",
    "\n",
    "filenames = glob.glob(source_dir + '/*')\n",
    "\n",
    "visits_by_day = {}\n",
    "for filename in filenames:\n",
    "    day = os.path.basename(filename)[:10]\n",
    "    assert re.match(r'[0-9]{4}-[0-9]{2}-[0-9]{2}', day), filename\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        visits = json.load(f)\n",
    "        \n",
    "    visits_by_day[day] = visits\n",
    "\n",
    "with open('visits_by_day.json', 'w') as f:\n",
    "    json.dump(visits_by_day, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clean keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elections'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_keyword(keyword):\n",
    "    return unidecode(keyword.lower())\n",
    "\n",
    "clean_keyword('Eléctions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('visits_by_day.json', 'r') as f:\n",
    "    visits_by_day = json.load(f)\n",
    "\n",
    "visits_by_day2 = {}\n",
    "for day, visits in visits_by_day.items():\n",
    "    visits2 = []    \n",
    "    for visit in visits:\n",
    "        visit2 = []\n",
    "        for kind, value in visit:\n",
    "            if (kind == 'keyword'):\n",
    "                visit2.append((kind, clean_keyword(value)))\n",
    "            else:\n",
    "                visit2.append((kind, value))\n",
    "        visits2.append(visit2)\n",
    "    visits_by_day2[day] = visits2\n",
    "    \n",
    "with open('visits_by_day2.json', 'w') as f:\n",
    "    json.dump(visits_by_day2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
